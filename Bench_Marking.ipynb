{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib psutil tqdm\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "import psutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "report_lines = []\n",
    "report_lines.append(f\"=== SYSTEM & GPU REPORT ===\")\n",
    "report_lines.append(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "# --- System Info ---\n",
    "report_lines.append(\"### SYSTEM INFO ###\")\n",
    "os_info = f\"{platform.system()} {platform.release()} ({platform.version()})\"\n",
    "cpu_name = platform.processor()\n",
    "physical_cores = psutil.cpu_count(logical=False)\n",
    "logical_cores = psutil.cpu_count(logical=True)\n",
    "ram_gb = round(psutil.virtual_memory().total / 1024**3, 2)\n",
    "\n",
    "report_lines.append(f\"OS: {os_info}\")\n",
    "report_lines.append(f\"Processor: {cpu_name}\")\n",
    "report_lines.append(f\"CPU Cores: {physical_cores} physical / {logical_cores} logical\")\n",
    "report_lines.append(f\"RAM: {ram_gb} GB\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "# --- GPU Info ---\n",
    "if torch.cuda.is_available():\n",
    "    report_lines.append(\"### GPU INFO (CUDA) ###\")\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    report_lines.append(f\"Number of GPUs: {n_gpus}\")\n",
    "\n",
    "    for i in range(n_gpus):\n",
    "        prop = torch.cuda.get_device_properties(i)\n",
    "        gpu_name = prop.name\n",
    "        gpu_vram = prop.total_memory / 1024**3\n",
    "        report_lines.append(f\"\\n--- GPU {i} ---\")\n",
    "        report_lines.append(f\"Name: {gpu_name}\")\n",
    "        report_lines.append(f\"Total VRAM: {gpu_vram:.2f} GB\")\n",
    "        report_lines.append(f\"Compute Capability: {prop.major}.{prop.minor}\")\n",
    "        report_lines.append(f\"CUDA Cores (estimate): {prop.multi_processor_count * 64}\")\n",
    "        clock_rate = getattr(prop, \"clock_rate\", None)\n",
    "        report_lines.append(f\"Clock Rate: {clock_rate / 1e3:.0f} MHz\" if clock_rate else \"Clock Rate: Not available\")\n",
    "        report_lines.append(f\"CUDA Version (torch): {torch.version.cuda}\")\n",
    "else:\n",
    "    report_lines.append(\"### GPU INFO ###\")\n",
    "    report_lines.append(\"No CUDA-capable GPU detected.\")\n",
    "    gpu_name = \"None\"\n",
    "    gpu_vram = 0\n",
    "report_lines.append(\"\")\n",
    "\n",
    "# --- Benchmark ---\n",
    "report_lines.append(\"### PERFORMANCE BENCHMARK (Matrix Multiply) ###\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device Selected: \", device)\n",
    "sizes = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "times = []\n",
    "\n",
    "try:\n",
    "    for size in tqdm(sizes, desc=\"Benchmarking Matrix Multiply\"):\n",
    "        a = torch.randn((size, size), device=device)\n",
    "        b = torch.randn((size, size), device=device)\n",
    "        torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "        t0 = time.time()\n",
    "        _ = torch.matmul(a, b)\n",
    "        torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "        t1 = time.time()\n",
    "        elapsed = t1 - t0\n",
    "        times.append(elapsed)\n",
    "        report_lines.append(f\"{size}x{size} multiply time: {elapsed:.4f} sec\")\n",
    "        del a, b\n",
    "        torch.cuda.empty_cache()\n",
    "except Exception as e:\n",
    "    report_lines.append(f\"Benchmark failed: {e}\")\n",
    "\n",
    "total_time = sum(times)\n",
    "report_lines.append(\"\")\n",
    "report_lines.append(f\"üîÅ Total Matrix Multiply Time: {total_time:.4f} seconds\")\n",
    "\n",
    "# --- Compute Overall Score ---\n",
    "cpu_score = min(25, physical_cores * 1.0)\n",
    "ram_score = min(20, ram_gb * 0.25)\n",
    "gpu_score = min(25, gpu_vram * 1.0)\n",
    "\n",
    "if total_time <= 1.0:\n",
    "    benchmark_score = 30\n",
    "elif total_time <= 1.5:\n",
    "    benchmark_score = 25\n",
    "elif total_time <= 2.0:\n",
    "    benchmark_score = 20\n",
    "elif total_time <= 3.0:\n",
    "    benchmark_score = 15\n",
    "elif total_time <= 5.0:\n",
    "    benchmark_score = 10\n",
    "else:\n",
    "    benchmark_score = 5\n",
    "\n",
    "total_score = round(cpu_score + ram_score + gpu_score + benchmark_score, 2)\n",
    "\n",
    "# --- Assign Tier Marker ---\n",
    "if total_score >= 90:\n",
    "    tier = \"üöÄ Extreme Workstation ‚Äì Top 1% elite performance\"\n",
    "elif total_score >= 80:\n",
    "    tier = \"üî• Heavy ML/Gaming Machine ‚Äì Very powerful\"\n",
    "elif total_score >= 65:\n",
    "    tier = \"‚öôÔ∏è Mid-Range Research Rig ‚Äì Balanced, capable\"\n",
    "elif total_score >= 50:\n",
    "    tier = \"üß™ Entry-Level ML Machine ‚Äì Good for prototyping\"\n",
    "elif total_score >= 30:\n",
    "    tier = \"üê¢ Basic Productivity System ‚Äì Limited ML use\"\n",
    "else:\n",
    "    tier = \"‚ùå Low-Grade System ‚Äì Not suitable for ML/DL workloads\"\n",
    "\n",
    "# --- Add Score and Tier to Report ---\n",
    "report_lines.append(\"\")\n",
    "report_lines.append(\"üèÅ OVERALL SYSTEM PERFORMANCE SCORE\")\n",
    "report_lines.append(f\"CPU Score:       {cpu_score:.2f} / 25\")\n",
    "report_lines.append(f\"RAM Score:       {ram_score:.2f} / 20\")\n",
    "report_lines.append(f\"GPU Score:       {gpu_score:.2f} / 25\")\n",
    "report_lines.append(f\"Benchmark Score: {benchmark_score:.2f} / 30\")\n",
    "report_lines.append(f\"‚≠ê TOTAL SCORE:   {total_score:.2f} / 100\")\n",
    "report_lines.append(f\"üéØ SYSTEM TIER:   {tier}\")\n",
    "\n",
    "# --- Add Tier Mapping Table ---\n",
    "report_lines.append(\"\\n### SYSTEM TIER MAPPING ###\")\n",
    "report_lines.append(\"Score Range     | Tier\")\n",
    "report_lines.append(\"--------------- | --------------------------------------------\")\n",
    "report_lines.append(\"90‚Äì100          | üöÄ Extreme Workstation ‚Äì Top 1% elite performance\")\n",
    "report_lines.append(\"80‚Äì89           | üî• Heavy ML/Gaming Machine ‚Äì Very powerful\")\n",
    "report_lines.append(\"65‚Äì79           | ‚öôÔ∏è Mid-Range Research Rig ‚Äì Balanced, capable\")\n",
    "report_lines.append(\"50‚Äì64           | üß™ Entry-Level ML Machine ‚Äì Good for prototyping\")\n",
    "report_lines.append(\"30‚Äì49           | üê¢ Basic Productivity System ‚Äì Limited ML use\")\n",
    "report_lines.append(\"< 30            | ‚ùå Low-Grade System ‚Äì Not suitable for ML/DL\")\n",
    "\n",
    "# --- Save Report ---\n",
    "with open(\"gpu_report.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(report_lines))\n",
    "\n",
    "# --- Save Matrix Benchmark Plot ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sizes, times, marker='o')\n",
    "plt.title(\"Matrix Multiplication Time vs Size\")\n",
    "plt.xlabel(\"Matrix Size (N x N)\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"gpu_benchmark.png\")\n",
    "\n",
    "# --- Save Score Radar Chart ---\n",
    "labels = ['CPU', 'RAM', 'GPU', 'Benchmark']\n",
    "scores = [cpu_score, ram_score, gpu_score, benchmark_score]\n",
    "max_scores = [25, 20, 25, 30]\n",
    "angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\n",
    "scores += scores[:1]\n",
    "max_scores += max_scores[:1]\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "ax.plot(angles, scores, 'o-', linewidth=2, label='System Score')\n",
    "ax.fill(angles, scores, alpha=0.25)\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "ax.set_title(f\"System Performance Radar\\n{tier}\", fontsize=12)\n",
    "ax.set_ylim(0, max(max_scores))\n",
    "ax.grid(True)\n",
    "plt.savefig(\"system_score_radar.png\")\n",
    "\n",
    "print(\"‚úÖ Report saved to gpu_report.txt\")\n",
    "print(\"‚úÖ Benchmark plot saved as gpu_benchmark.png\")\n",
    "print(\"‚úÖ Score radar chart saved as system_score_radar.png\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
